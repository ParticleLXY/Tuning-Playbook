# 深度学习调参指南

## 1. 这份文档的受众

这份文档的受众是那些**想让他们的深度学习模型获得最佳性能**的工程人员和研究人员。我们假设读者已经掌握了基本的机器学习和深度学习的知识。

文档的重点是**模型超参数的优化**。我们也谈及了深度学习训练的其他方面，如流水线的部署和优化，但我们不打算深入这些问题。

我们假设文中机器学习处理的任务都是监督学习任务，或看起来像监督学习的任务（如自监督学习）。也就是说，文中提及的某些策略也适用于其他类型的任务。

## 2. 开始一个新项目的指南

在调参过程中，很多决定只需要在项目开始时定下，并且在情况发生变化时才会偶尔考虑修改。

我们的指南基于以下几个前提：

- 明确任务、数据清洗等准备工作已经完成，花点时间在模型的结构和训练的配置上是有意义的。
- 已有一个用于训练和评估的流水线，并且这个流水线适用于多个想要测试的模型。
- 选择恰当的评价指标，这个指标应该尽可能贴近部署的环境。

### 2.1 选择模型结构

*太长不看：当开始一个新的工程时，首先尝试一个已经验证过的模型。*

- 首先选择一个完善的、常用的模型结构开始你的工作。以后总有机会搭建一个自定义模型。
- 一个模型结构具有各种超参数来确定它的大小和其他细节（如层数、层宽、激活函数的类型等）
  - 因此，选择一个结构意味着选择了一系列不同的模型（根据模型超参数的不同）
  - 在xx和xx中描述了如何选择模型的超参数
- 如果可能，尝试找到一篇尽可能接近你所进行项目的论文并以这篇论文的模型为起点并复现它。

### 2.2 选择优化器

*太长不看：以一个针对当前项目最常用的优化器开始。*

- 没有一个面向所有的机器学习问题和模型结构的最好的优化器。比较不同优化器的性能是一项艰巨的任务。
- 我们建议坚持使用成熟的、流行的优化器，尤其是开始一个新项目时。
  - 理想情况下，选择用于同一类问题的最流行的优化器。
- 准备好关注所选优化器的所有超参数
  - 拥有越多超参数的优化器可能需要更多次的调参来找到最好的配置。
  - 尝试去找到其他超参数（如模型结构的超参数）的最优值而把优化器的超参数当作nuisance参数，尤其是在项目的开始阶段。
  - 在项目的初期，最好选择一个简单的优化器（如固定动量的SGD或固定$\epsilon$、$\beta_1$、$\beta_2$的Adam），在之后再去选择一个更适用的优化器。
- 我们喜欢的优化器（包括但不限于）：
  - 带动量的SGD（我们喜欢Nesterov变体）
  - Adam和NAdam，他们带有动量，而且比SGD更通用。Adam有4个超参数，而且它们都很重要！
    - 请参阅如何调整Adam的超参数

### 2.3 选择batch size

*太长不看：batch size控制着训练速度，不应该直接用来调整验证集的性能。通常，理想的batch size是硬件支持的最大batch size。*

- batch size是影响训练速度和计算资源消耗的关键因素。
- 增大batch size通常能缩短训练时间，这是非常有益的，因为：
  - 允许在有限时间里更充分地调参，最终的模型性能可能会更好。
  - 减少了开发周期的延迟，允许更频繁地实验新想法。
- 增加batch size可能会减少、增加或不改变资源消耗。
- batch size不应被视为一个影响验证集性能的可调超参数。
  - 只要所有的超参数都经过良好的调整（尤其是学习率和正则化），并且迭代次数足够，任意大小的batch size都将有相同的最终性能。
  - 请参阅为什么batch size不应被调整来改进验证集性能。

#### 2.3.1 确定可行的batch size并评估训练吞吐量(training throughput)

- 对一个给定的模型和优化器，硬件支持一系列的batch size。限制batch size的通常是显存。
- 不幸的是，如果不运行，或至少编译完整的训练程序，我们很难计算出合适的batch size。
- 最简单的解决方案是执行一系列batch size不同（通常以2的幂次增加）的训练任务，直到显存溢出。
- 对于每个batch size，我们应该训练足够长的时间来获得训练吞吐量的可靠估计

<center>训练吞吐量 = 每秒处理的样本数</center>

<center>也等价于每个训练步消耗的时间(time per step)</center>

<center>time per step = batch size / training throughput</center>

- 显存没有饱和的情况下，如果batch size增加一倍，训练吞吐量也会增加一倍，time per step基本保持不变。
- 如果不是上述的情况，则说明训练流水线存在瓶颈，如I/O或计算节点之间的同步。对此值得在继续之前对其进行诊断和纠正。
- 如果训练吞吐量在某个batch size后就不再增加，即使显存支持更大的batch size，我们也只能保持当前的batch size。
  - 只有增加batch size能带来吞吐量的增加，增大batch size才是有益的。如果没能增加吞吐量，去解决限制其的瓶颈或使用更小的batch size
  - Gradient accumulation模拟了比硬件支持的更大的batch size，但不能带来吞吐量上的任何好处，因此在工作中应该尽可能的避免。
- 在更改了模型或优化器之后，都需要重复上述的步骤。

#### 2.3.2 选择使训练时间最短的batch size

<center>Training time = (time per step) * (total number of steps)</center>

- 对于所有可行的batch size，在没有并行计算的开销和训练瓶颈时，我们一般假设time per step相等。实际上，增加batch size会带来一些额外的开销。
- 随着batch size的增加，达到特定性能所需要的training steps会减少（前提是修改batch size后调整所有相关的超参数）。
  - 完美缩放：batch size增加一倍，training steps减半。
  - 完美缩放适用于临界batch size下的所有batch size，超过临界batch size，收益会递减。
  - 最终，增加batch size不再减少training steps（但永远不会增加）。
- 因此，最小化训练时间的方法一般是采用临界batch size。

  - 临界batch size的大小取决于数据集、模型和优化器，如何通过计算得到它仍然是一个悬而未决的问题。
  - 当比较batch size时，注意区分一个样本的消耗、一个epoch的消耗和一个step的消耗之间的区别。
    - 只在完美缩放的范围内比较不同batch size下的epoch消耗，即使更大的batch size仍能缩短训练时间。
  - 通常情况下，硬件支持的最大batch size也小于临界batch size。所以一个通用准则是，尽可能选择最大的batch size。
- 不应该使用一个会增加训练时间的batch size。

#### 2.3.3 选择资源消耗最小的batch size

- 增大batch size会带来以下两类的资源消耗：
  1. 前期成本，如购买新硬件或重写训练流水线以支持多GPU/TPU。
  2. 使用成本，如团队预算，云服务的费用，电费，维护成本。



#### 2.3.4 修改batch size后需要对大部分超参数进行重新调参

- 大部分超参数对batch size敏感，所以修改batch size后需要对他们进行重新调参。
- 优先级最高的是优化器超参数和正则化超参数，因为它们与batch size强相关。
- 在项目初期选择batch size时请注意，如果以后要改变batch size，为新的batch size调整超参数可能会十分困难，耗时且成本高昂。

#### 2.3.5 batch norm和batch size的交互关系

- batch norm很复杂，通常来说，计算统计数据的batch size与计算梯度的batch size不同，详情请见batch norm部分。

### 2.4 选择初始配置

- 在对超参数进行调参前，我们需要确定起点，包括：
  1. 模型的结构（如层数）
  2. 优化器超参数（如学习率）
  3. training steps
- 确定初始配置需要反复实验。
- 我们的指导原则是找到一个简单、相对快速、资源消耗相对较低的配置，从而得到一个合理的结果。
  - 简单意味着尽可能避免花里胡哨的东西，这些可以在后期再加进去，即使花里胡哨的东西在后来被证明是有用的。
    - 例如，初始配置为固定学习率而不是花哨的衰减策略。
  - 选择快速且消耗最少资源的初始配置将使超参数调参更加高效。
    - 例如，从一个小模型开始。
  - 合理的表现视问题而定，但至少意味着经过训练的模型在验证集上的性能比随机好得多（尽管它可能很糟糕而不值得部署）。
- 选择合适的training steps需要平衡以下几点：
  - 一方面，训练更多steps可以改进模型性能并让调参更容易。
  - 另一方面，更少的training steps会让训练进程更快，也占用更少的资源，进行更多轮的训练吗，从而让调参更有效率。此外，如果一开始选择了一个不合适的training step，中途改变也不是很容易，例如根据training step制定的学习率衰减策略。

## 3. 提高模型性能的科学方法

机器学习开发的最终目的是最大化部署模型的效果。尽管很多开发过程因使用场景而异（如时长、可用的计算资源、模型的类型等），但有相同的开发步骤和准则。

这份指南基于以下假设：

- 有一个充分运行的训练流水线和一个可以获得合理结果的训练配置。
- 有足够的计算资源进行有意义的调参实验并且可以并行运行多个训练任务。

### 3.1 增量调参策略

*太长不看：从一个简单的配置开始，随着对问题了解的深入，逐步进行改进。确保任何改进都是基于强有力的证据，以避免增加不必要的复杂性。*

- 我们的终极目标是找到一组使模型表现最好的配置。
  - 某些情况下，我们的目标是在deadline之前尽可能的优化模型（如，参加一场比赛）。
  - 其他情况下，我们希望能不断地改进模型（如，不断地改进一个部署的模型）。
- 理论上，我们可以用算法自动搜索空间内所有可能的配置来最大化性能，但这不具有可行性。
  - 可能的配置相当的多，目前还没有一个足够复杂的算法在没有人类指导的情况下进行有效的搜索。
- 大部分自动搜索算法都依赖于手动设计的搜索空间，这些搜索空间非常重要。
- 最有效的方法是从一个简单的配置开始，随着对问题了解的深入，逐步进行改进。
  - 我们在每一轮调参中都使用自动搜索算法，随着我们理解的加深，不断更新搜索空间。
- 随着我们的探索，我们自然会找到越来越好的配置，因此能不断改进我们的模型。
  - 我们把更新我们最佳配置的行为称为launch。
  - 我们每一次的launch都是基于强有力的证据，而不是基于运气，这样就不会给训练流水线增加不必要的复杂性。

总的来说，我们的调参基于重复以下四个步骤：

1. 为下一轮实验确定合适的目标。
2. 设计并进行一系列实验来逼近目标。
3. 从结果中了解我们能做些什么。
4. 考虑是否更新最佳配置。

### 3.2 探索 vs 开发

*太长不看：大多数时候，我们的主要目标都是深入了解问题。*

- 尽管可能有人认为我们会花费大部分时间来最大化验证集性能，但实际上我们花费了大部分时间来尝试深入了解问题，仅有小部分时间关注验证集错误率。
  
  - 换句话说，我们花费大部分时间进行探索，小部分时间进行开发。
  
- 长远来看，如果想最大化性能，理解问题至关重要。将注意力放在短期收益之上可以帮助我们：
  - 避免仅通过历史记录就对运行良好的模型进行不必要的配置更新。
  - 确定哪些超参数对验证集误差敏感，哪些超参数互相影响因此需要一起进行调整，哪些超参数对调整不敏感因此可以在未来的实验里进行调整。
  - 建议尝试新功能，例如出现过拟合时使用新的正则化器。
  - 区分没有帮助、可以移除的特征，减少未来实验的复杂性。
  - 识别来自调参带来的提升何时可能已经饱和。
  
  - 围绕最佳值缩小搜索空间，以提高搜索效率。
  
- 当我们完成上述工作后，我们可以开始关注验证集误差，即使之前的实验没有完全暴露出调参的问题。

### 3.3 选择下一轮实验的目标

*太长不看：*

- 每轮实验都需要有一个明确的目标，而且目标范围要足够窄。如果试图一次添加多个特征或解决多个问题，那么我们就无法理清这些特征/问题之间的相互影响。
- 目标示例：
  - 尝试对流水线进行改进（如新的正则化器、预处理的选择等）
  - 理解一个模型超参数造成的影响（如激活函数）
  - 最小化验证集误差

### 3.4 设计下一轮实验

#### 3.4.1 识别科学的、讨厌的、固定的超参数

- 针对给定的目标，所有超参数都可以被区分为科学的、讨厌的或固定的。
  - 科学的超参数是对模型性能有影响的参数。
  - 讨厌的超参数是那些需要被优化，以便能公平的比较科学超参数的参数。
  - 固定的超参数是那些在本轮实验中固定值的参数。这些超参数一般是在比较科学超参数时，没必要或不想要改变的参数。
    - 我们通过固定一组参数得出的结论可能不适于另一组固定参数的情况。
  
- 举例来说，如果我们的目标是“验证是否具有更多隐藏层的模型验证集误差更小”，那么科学超参数就是隐藏层的数目。
  - 学习率此时是个讨厌的超参数，因为只有对不同隐藏层大小的模型分别调整学习率，才能公平的比较不同隐藏层大小模型的性能（最佳学习率通常取决于模型结构）。
  - 如果我们在之前的实验中确定了激活函数的选择对模型深度不敏感，或我们愿意限制我们关于隐藏层数量的结论以仅涵盖特定的情况，那么激活函数是一个固定超参数。如果我们对不同的隐藏层单独调整激活函数，那么它就是一个讨厌的超参数。
  
- 超参数的类别取决于我们的目标，并不是超参数的固有属性。
  - 举例来说，激活函数可以是科学的（ReLU和tanh哪一个更好），可以是讨厌的（不限制激活函数的情况下，5层的模型是不是比6层的更好），也可以是固定的（对ReLU而言，增加BN层会不会有帮助）。
  
- 在设计新一轮实验时，我们首先要筛选出科学的超参数。
  - 在这一步，其他所有的超参数都被视为讨厌的。
  
- 接着，我们固定一些超参数。
  - 如果资源不受限制，可以把除科学超参数之外其他所有的超参数都视为讨厌的，那么我们的结论就不会受到固定超参数的限制。
  - 但是，需要优化的讨厌超参越多，工作量就越大，得出错误结论的风险也就越大。
    - 如下文要讲的，我们可以通过增加计算资源的预算来降低风险，但是一般我们能获取的最大计算资源，也小于遍历讨厌超参所需要的计算资源。
  - 如果我们判断，修正一个固定超参对我们结论的限制的成本，小于我们把它视为一个讨厌超参而进行调参的成本，我们会把这个超参设为固定超参。
    - 一个讨厌超参与科学超参的交互越多，固定它带来的负面影响就越大。例如，权重衰减的最佳值通常取决于模型的大小，所以在比较不同大小模型的性能时固定权重衰减不是一个好主意。
  
- 尽管分配给每个超参数的类型取决于实验目标，但我们对某些类别的超参数有以下经验法则：
  - 各种优化器的超参数（如学习率、动量、学习率调度器参数、Adam $\beta$等，至少其中的一些是令人讨厌的超参数，因为它们与其他变化的交互作用最大。
    - 这些超参数很少是科学超参数，因为像“当前的流水线的最佳学习率是多少”这样的目标没有给出多少参考。最佳设置很容易随着流水线的变动而改变。
    - 尽管由于资源限制或当有特别有力的证据表明它们不与科学超参数相互作用时，偶尔会固定其中的一些参数。但通常应该假设优化器超参数必须单独调整以在不同设置之间对科学的超参数进行公平比较，因此优化器超参数不应该被固定。
      - 此外，没有任何先验理由偏爱一个优化器超参数值而不是另一个（例如，它们通常不会以任何方式影响正向传递或梯度的计算成本）。
  - 对优化器的选择通常是科学超参数或固定超参数。
    - 如果我们的实验目标涉及在两个或多个有坏去直接的公平比较（如确定哪个优化器在给定的steps中产生最小的验证误差），那么它就是一个科学超参数。
    - 出于各种原因，我们也可以将其设置为固定的超参数，包括
      1. 先前的实验让我们相信优化器对于当前的科学超参数不敏感；
      2. 某个优化器的训练曲线更容易理解，因此可以来对比其他超参数的值；
      3. 某个优化器相比其他使用更少的内存。
  - 正则化技术引入的超参数一般是令人讨厌的超参数，但是是否使用正则化是一个科学超参数或固定超参数。
    - 例如，dropout增加了代码的复杂性，因此可以把是否使用dropout作为一个科学超参数；但dropout rate是一个讨厌的超参数。
      - 如果我们决定把dropout加入训练流水线，那么在未来的实验中，dropout rate就是一个讨厌的超参数。
  - 模型结构的超参数通常是科学的或固定的超参数，因为模型架构的变化会影响部署和训练的成本，延迟和内存需求。
    - 例如，层数通常是一个科学的或固定的超参数，因为它往往会对训练速度和内存使用产生巨大影响。
  
- 某些情况下，讨厌的和固定的超参数集取决于科学超参数的值。

  - 例如，我们试图确定Nesterov momentum和Adam哪个优化器的验证误差最小，那么科学超参数就是优化器的选择：`{"Nesterov_momentum", "Adam"}`，当优化器是Nesterov momentum时，就引入了讨厌的/固定的超参数`{learning_rate, momentum}`，当优化器是Adam时，就引入了讨厌的/固定的超参数`{learning_rate, beta1, beta2, epsilon}`。

  - 仅针对科学超参数的某些值存在的超参数成为条件超参数。

    我们不应该仅仅因为两个条件超参数具有相同的名称就认为它们是相同的。 在上面的示例中，对于`optimizer="Nesterov_momentum"` 与 `optimizer="Adam"` ，`learning_rate`是不同的条件超参数。 它在两种算法中的作用相似（尽管不完全相同），但在每个优化器中运行良好的值范围通常相差几个数量级。


#### 3.4.2 进行一系列实验

